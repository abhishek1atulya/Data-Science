{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gaa7OgL-TdPa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "35b3pUI1Turc",
    "outputId": "3c807f30-7d6d-47b7-c480-5279e1c00e27"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTASXrxUTyeW",
    "outputId": "d9cf3bff-ebfd-4820-ebf3-765736e55502"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "VMgbJGUOT_SX"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['id', 'Unnamed: 32'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "43Yhb8eVUXeE",
    "outputId": "21bee579-02e1-491e-9ab9-2829d38b2330"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1G7UWSTSM4M"
   },
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "rMX3fS-xUjDp"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4b4HNCjlSRwF"
   },
   "source": [
    "### scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "9U6kQsjTU5ZE"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMmrSA88VMZQ",
    "outputId": "9e02d984-268a-4484-d623-fb4fdf4fba8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06714829, -2.03725513,  1.23611461, ...,  2.2589165 ,\n",
       "         2.72799946,  1.90880767],\n",
       "       [-0.71485169, -0.25160597, -0.6458541 , ...,  0.40204934,\n",
       "        -0.37446057,  0.48010642],\n",
       "       [ 1.66581076,  2.05371289,  1.57666905, ...,  0.72002659,\n",
       "        -0.51511822, -0.95568381],\n",
       "       ...,\n",
       "       [ 1.76372285,  0.4992824 ,  1.6293739 , ...,  0.44554622,\n",
       "        -1.0489779 , -0.68848395],\n",
       "       [-0.11339173,  0.68929379, -0.06812782, ...,  0.78752176,\n",
       "         0.29685999,  0.51446069],\n",
       "       [-0.35957069, -1.40998863, -0.42246661, ..., -0.9169563 ,\n",
       "        -0.93549276, -0.80408879]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "uYoHEPdsVX3P",
    "outputId": "dfd363bb-7262-492b-e5e1-facf17ff1ea8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "469    B\n",
       "565    M\n",
       "516    M\n",
       "283    M\n",
       "      ..\n",
       "544    B\n",
       "105    M\n",
       "237    M\n",
       "196    M\n",
       "287    B\n",
       "Name: diagnosis, Length: 455, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XhX--USSU5q"
   },
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "xleQoeKbVafX"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHQJ5QegVtdF",
    "outputId": "ebd2b12e-415d-4d58-f82a-3b015f3d0fd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZ4_HRZcSZwa"
   },
   "source": [
    "### Numpy arrays to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "CHvyHOq9VuTE"
   },
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train)\n",
    "X_test_tensor = torch.from_numpy(X_test)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "y_test_tensor = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KRGQrGrWWQNN",
    "outputId": "bf185584-3d6f-47dd-e640-d95cbfbb656c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXkt8Mq_WR_I",
    "outputId": "a7c7bd37-6e9d-4caf-def1-f7e3310931ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qv0fhQa1Sfx8"
   },
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# help(torch.normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "normal() got an unexpected keyword argument 'Random_State'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[272], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m l \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnormal(mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,size\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64,Random_State\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m      2\u001b[0m l\n",
      "\u001b[1;31mTypeError\u001b[0m: normal() got an unexpected keyword argument 'Random_State'"
     ]
    }
   ],
   "source": [
    "l = torch.normal(mean=0,std=1,size= (1,2), requires_grad=True, dtype=torch.float64)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4337, 1.7725]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.seed=55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function normal in module torch:\n",
      "\n",
      "normal(...)\n",
      "    normal(mean, std, *, generator=None, out=None) -> Tensor\n",
      "\n",
      "    Returns a tensor of random numbers drawn from separate normal distributions\n",
      "    whose mean and standard deviation are given.\n",
      "\n",
      "    The :attr:`mean` is a tensor with the mean of\n",
      "    each output element's normal distribution\n",
      "\n",
      "    The :attr:`std` is a tensor with the standard deviation of\n",
      "    each output element's normal distribution\n",
      "\n",
      "    The shapes of :attr:`mean` and :attr:`std` don't need to match, but the\n",
      "    total number of elements in each tensor need to be the same.\n",
      "\n",
      "    .. note:: When the shapes do not match, the shape of :attr:`mean`\n",
      "              is used as the shape for the returned output tensor\n",
      "\n",
      "    .. note:: When :attr:`std` is a CUDA tensor, this function synchronizes\n",
      "              its device with the CPU.\n",
      "\n",
      "    Args:\n",
      "        mean (Tensor): the tensor of per-element means\n",
      "        std (Tensor): the tensor of per-element standard deviations\n",
      "\n",
      "    Keyword args:\n",
      "        generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n",
      "        out (Tensor, optional): the output tensor.\n",
      "\n",
      "    Example::\n",
      "\n",
      "        >>> torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))\n",
      "        tensor([  1.0425,   3.5672,   2.7969,   4.2925,   4.7229,   6.2134,\n",
      "                  8.0505,   8.1408,   9.0563,  10.0566])\n",
      "\n",
      "    .. function:: normal(mean=0.0, std, *, out=None) -> Tensor\n",
      "       :noindex:\n",
      "\n",
      "    Similar to the function above, but the means are shared among all drawn\n",
      "    elements.\n",
      "\n",
      "    Args:\n",
      "        mean (float, optional): the mean for all distributions\n",
      "        std (Tensor): the tensor of per-element standard deviations\n",
      "\n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "\n",
      "    Example::\n",
      "\n",
      "        >>> torch.normal(mean=0.5, std=torch.arange(1., 6.))\n",
      "        tensor([-1.2793, -1.0732, -2.0687,  5.1177, -1.2303])\n",
      "\n",
      "    .. function:: normal(mean, std=1.0, *, out=None) -> Tensor\n",
      "       :noindex:\n",
      "\n",
      "    Similar to the function above, but the standard deviations are shared among\n",
      "    all drawn elements.\n",
      "\n",
      "    Args:\n",
      "        mean (Tensor): the tensor of per-element means\n",
      "        std (float, optional): the standard deviation for all distributions\n",
      "\n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor\n",
      "\n",
      "    Example::\n",
      "\n",
      "        >>> torch.normal(mean=torch.arange(1., 6.))\n",
      "        tensor([ 1.1552,  2.6148,  2.6535,  5.8318,  4.2361])\n",
      "\n",
      "    .. function:: normal(mean, std, size, *, out=None) -> Tensor\n",
      "       :noindex:\n",
      "\n",
      "    Similar to the function above, but the means and standard deviations are shared\n",
      "    among all drawn elements. The resulting tensor has size given by :attr:`size`.\n",
      "\n",
      "    Args:\n",
      "        mean (float): the mean for all distributions\n",
      "        std (float): the standard deviation for all distributions\n",
      "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "\n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "\n",
      "    Example::\n",
      "\n",
      "        >>> torch.normal(2, 3, size=(1, 4))\n",
      "        tensor([[-1.3987, -1.9544,  3.6048,  0.7909]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# help(torch.normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "id": "tNrloSpuSkwk"
   },
   "outputs": [],
   "source": [
    "class MySimpleNN():\n",
    "\n",
    "  def __init__(self, X):\n",
    "\n",
    "    self.weights1 = torch.normal(0,1, size=(X.shape[1], 16), dtype=torch.float64, requires_grad=True)\n",
    "    self.weights2 = torch.normal(0,1, size=(16, 8), dtype = torch.float64, requires_grad = True)\n",
    "    self.weights3 = torch.normal(0,1, size=(8, 1), dtype= torch.float64, requires_grad = True)\n",
    "    # self.weights4 = torch.rand(4,1, dtype= torch.float64, requires_grad = True)\n",
    "    self.bias1 = torch.zeros(16, dtype=torch.float64, requires_grad=True)\n",
    "    self.bias2 = torch.zeros(8, dtype=torch.float64, requires_grad=True)\n",
    "    self.bias3 = torch.zeros(1, dtype=torch.float64, requires_grad=True)\n",
    "    # self.bias4 = torch.zeros(1, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "  def forward(self, X):\n",
    "    x = torch.matmul(X, self.weights1) + self.bias1\n",
    "    x = torch.tanh(x)\n",
    "    y = torch.matmul(x, self.weights2) + self.bias2\n",
    "    y = torch.tanh(y)\n",
    "    z = torch.matmul(y, self.weights3) + self.bias3\n",
    "    # f = torch.tanh(z)\n",
    "    # f = torch.matmul(z, self.weights4) + self.bias4\n",
    "    y_pred = torch.sigmoid(z)\n",
    "    return y_pred\n",
    "\n",
    "  def loss_function(self, y_pred, y):\n",
    "    # Clamp predictions to avoid log(0)\n",
    "    epsilon = 1e-7\n",
    "    y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = -(y_train_tensor * torch.log(y_pred) + (1 - y_train_tensor) * torch.log(1 - y_pred)).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gn_QAecdLJF"
   },
   "source": [
    "### Important Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "id": "xkfjyefSXHcv"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IiXlBkKdONn"
   },
   "source": [
    "### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GxPsNM2_XQev",
    "outputId": "6a6eeb37-8fec-489e-8213-7522851f6b16",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.4233703949265597\n",
      "Epoch: 2, Loss: 1.387110410920686\n",
      "Epoch: 3, Loss: 1.3528372600329106\n",
      "Epoch: 4, Loss: 1.3209171549070307\n",
      "Epoch: 5, Loss: 1.2915426620230213\n",
      "Epoch: 6, Loss: 1.2646349029510673\n",
      "Epoch: 7, Loss: 1.239930191282827\n",
      "Epoch: 8, Loss: 1.2171505276594445\n",
      "Epoch: 9, Loss: 1.1961218180057835\n",
      "Epoch: 10, Loss: 1.1767474159314062\n",
      "Epoch: 11, Loss: 1.1588941655020624\n",
      "Epoch: 12, Loss: 1.1423641862936285\n",
      "Epoch: 13, Loss: 1.1269583738722222\n",
      "Epoch: 14, Loss: 1.1125196544814009\n",
      "Epoch: 15, Loss: 1.0989362097015112\n",
      "Epoch: 16, Loss: 1.0861308065495288\n",
      "Epoch: 17, Loss: 1.0740491241954635\n",
      "Epoch: 18, Loss: 1.0626496940534402\n",
      "Epoch: 19, Loss: 1.0518960978822078\n",
      "Epoch: 20, Loss: 1.0417520037512438\n",
      "Epoch: 21, Loss: 1.0321790739071726\n",
      "Epoch: 22, Loss: 1.0231370048619484\n",
      "Epoch: 23, Loss: 1.0145846436436394\n",
      "Epoch: 24, Loss: 1.0064813427864578\n",
      "Epoch: 25, Loss: 0.998788120321645\n",
      "Epoch: 26, Loss: 0.9914684975562703\n",
      "Epoch: 27, Loss: 0.9844890326610941\n",
      "Epoch: 28, Loss: 0.9778196032146492\n",
      "Epoch: 29, Loss: 0.9714334784784785\n",
      "Epoch: 30, Loss: 0.9653072023632947\n",
      "Epoch: 31, Loss: 0.959420302053077\n",
      "Epoch: 32, Loss: 0.9537548545135359\n",
      "Epoch: 33, Loss: 0.9482949787991563\n",
      "Epoch: 34, Loss: 0.9430263529583307\n",
      "Epoch: 35, Loss: 0.9379358500124019\n",
      "Epoch: 36, Loss: 0.9330113382699753\n",
      "Epoch: 37, Loss: 0.9282416238197525\n",
      "Epoch: 38, Loss: 0.9236164688492685\n",
      "Epoch: 39, Loss: 0.9191266175907937\n",
      "Epoch: 40, Loss: 0.9147637888783937\n",
      "Epoch: 41, Loss: 0.9105206254293052\n",
      "Epoch: 42, Loss: 0.9063906095939543\n",
      "Epoch: 43, Loss: 0.9023679617019034\n",
      "Epoch: 44, Loss: 0.898447535312871\n",
      "Epoch: 45, Loss: 0.8946247189396561\n",
      "Epoch: 46, Loss: 0.8908953492199561\n",
      "Epoch: 47, Loss: 0.8872556371889699\n",
      "Epoch: 48, Loss: 0.8837021072992843\n",
      "Epoch: 49, Loss: 0.8802315478288388\n",
      "Epoch: 50, Loss: 0.8768409709537879\n",
      "Epoch: 51, Loss: 0.8735275807610964\n",
      "Epoch: 52, Loss: 0.8702887476492076\n",
      "Epoch: 53, Loss: 0.8671219878024825\n",
      "Epoch: 54, Loss: 0.8640249466660336\n",
      "Epoch: 55, Loss: 0.8609953855637575\n",
      "Epoch: 56, Loss: 0.8580311707839082\n",
      "Epoch: 57, Loss: 0.8551302646031232\n",
      "Epoch: 58, Loss: 0.8522907178354134\n",
      "Epoch: 59, Loss: 0.8495106635826675\n",
      "Epoch: 60, Loss: 0.8467883119330001\n",
      "Epoch: 61, Loss: 0.8441219454073968\n",
      "Epoch: 62, Loss: 0.8415099149972812\n",
      "Epoch: 63, Loss: 0.8389506366687138\n",
      "Epoch: 64, Loss: 0.8364425882350984\n",
      "Epoch: 65, Loss: 0.8339843065210986\n",
      "Epoch: 66, Loss: 0.8315743847571555\n",
      "Epoch: 67, Loss: 0.8292114701574156\n",
      "Epoch: 68, Loss: 0.826894261644669\n",
      "Epoch: 69, Loss: 0.8246215076945833\n",
      "Epoch: 70, Loss: 0.8223920042784608\n",
      "Epoch: 71, Loss: 0.8202045928892647\n",
      "Epoch: 72, Loss: 0.8180581586400131\n",
      "Epoch: 73, Loss: 0.8159516284270029\n",
      "Epoch: 74, Loss: 0.8138839691529101\n",
      "Epoch: 75, Loss: 0.8118541860067261\n",
      "Epoch: 76, Loss: 0.809861320798888\n",
      "Epoch: 77, Loss: 0.8079044503509174\n",
      "Epoch: 78, Loss: 0.8059826849395089\n",
      "Epoch: 79, Loss: 0.8040951667953692\n",
      "Epoch: 80, Loss: 0.8022410686572591\n",
      "Epoch: 81, Loss: 0.8004195923816986\n",
      "Epoch: 82, Loss: 0.7986299676086804\n",
      "Epoch: 83, Loss: 0.7968714504835619\n",
      "Epoch: 84, Loss: 0.7951433224350639\n",
      "Epoch: 85, Loss: 0.7934448890090559\n",
      "Epoch: 86, Loss: 0.7917754787575264\n",
      "Epoch: 87, Loss: 0.7901344421818811\n",
      "Epoch: 88, Loss: 0.7885211507294528\n",
      "Epoch: 89, Loss: 0.7869349958418772\n",
      "Epoch: 90, Loss: 0.785375388053774\n",
      "Epoch: 91, Loss: 0.7838417561400051\n",
      "Epoch: 92, Loss: 0.7823335463096116\n",
      "Epoch: 93, Loss: 0.7808502214444306\n",
      "Epoch: 94, Loss: 0.7793912603802844\n",
      "Epoch: 95, Loss: 0.7779561572285827\n",
      "Epoch: 96, Loss: 0.7765444207361369\n",
      "Epoch: 97, Loss: 0.7751555736809789\n",
      "Epoch: 98, Loss: 0.773789152301985\n",
      "Epoch: 99, Loss: 0.772444705760147\n",
      "Epoch: 100, Loss: 0.7711217956293723\n",
      "Epoch: 101, Loss: 0.769819995414777\n",
      "Epoch: 102, Loss: 0.768538890096507\n",
      "Epoch: 103, Loss: 0.7672780756972197\n",
      "Epoch: 104, Loss: 0.7660371588714623\n",
      "Epoch: 105, Loss: 0.7648157565152863\n",
      "Epoch: 106, Loss: 0.7636134953945592\n",
      "Epoch: 107, Loss: 0.7624300117905447\n",
      "Epoch: 108, Loss: 0.7612649511614419\n",
      "Epoch: 109, Loss: 0.760117967818696\n",
      "Epoch: 110, Loss: 0.7589887246170023\n",
      "Epoch: 111, Loss: 0.7578768926570403\n",
      "Epoch: 112, Loss: 0.7567821510000815\n",
      "Epoch: 113, Loss: 0.7557041863937211\n",
      "Epoch: 114, Loss: 0.7546426930080682\n",
      "Epoch: 115, Loss: 0.7535973721818343\n",
      "Epoch: 116, Loss: 0.7525679321778231\n",
      "Epoch: 117, Loss: 0.7515540879474124\n",
      "Epoch: 118, Loss: 0.7505555609036747\n",
      "Epoch: 119, Loss: 0.7495720787028417\n",
      "Epoch: 120, Loss: 0.748603375033867\n",
      "Epoch: 121, Loss: 0.7476491894158781\n",
      "Epoch: 122, Loss: 0.7467092670033434\n",
      "Epoch: 123, Loss: 0.7457833583988004\n",
      "Epoch: 124, Loss: 0.7448712194730106\n",
      "Epoch: 125, Loss: 0.7439726111924195\n",
      "Epoch: 126, Loss: 0.7430872994537951\n",
      "Epoch: 127, Loss: 0.7422150549259316\n",
      "Epoch: 128, Loss: 0.7413556528982903\n",
      "Epoch: 129, Loss: 0.7405088731364441\n",
      "Epoch: 130, Loss: 0.7396744997441845\n",
      "Epoch: 131, Loss: 0.7388523210321337\n",
      "Epoch: 132, Loss: 0.7380421293926901\n",
      "Epoch: 133, Loss: 0.7372437211811265\n",
      "Epoch: 134, Loss: 0.7364568966026381\n",
      "Epoch: 135, Loss: 0.7356814596051323\n",
      "Epoch: 136, Loss: 0.7349172177775315\n",
      "Epoch: 137, Loss: 0.7341639822533563\n",
      "Epoch: 138, Loss: 0.7334215676193432\n",
      "Epoch: 139, Loss: 0.7326897918288446\n",
      "Epoch: 140, Loss: 0.7319684761197561\n",
      "Epoch: 141, Loss: 0.7312574449367092\n",
      "Epoch: 142, Loss: 0.7305565258572717\n",
      "Epoch: 143, Loss: 0.7298655495218987\n",
      "Epoch: 144, Loss: 0.7291843495673754\n",
      "Epoch: 145, Loss: 0.72851276256351\n",
      "Epoch: 146, Loss: 0.7278506279528297\n",
      "Epoch: 147, Loss: 0.7271977879930503\n",
      "Epoch: 148, Loss: 0.7265540877020971\n",
      "Epoch: 149, Loss: 0.7259193748054651\n",
      "Epoch: 150, Loss: 0.7252934996857221\n",
      "Epoch: 151, Loss: 0.7246763153339613\n",
      "Epoch: 152, Loss: 0.7240676773030376\n",
      "Epoch: 153, Loss: 0.7234674436624217\n",
      "Epoch: 154, Loss: 0.722875474954523\n",
      "Epoch: 155, Loss: 0.7222916341523478\n",
      "Epoch: 156, Loss: 0.7217157866183698\n",
      "Epoch: 157, Loss: 0.7211478000644976\n",
      "Epoch: 158, Loss: 0.7205875445130439\n",
      "Epoch: 159, Loss: 0.7200348922586006\n",
      "Epoch: 160, Loss: 0.7194897178307466\n",
      "Epoch: 161, Loss: 0.7189518979575128\n",
      "Epoch: 162, Loss: 0.7184213115295449\n",
      "Epoch: 163, Loss: 0.7178978395649079\n",
      "Epoch: 164, Loss: 0.7173813651744877\n",
      "Epoch: 165, Loss: 0.7168717735279488\n",
      "Epoch: 166, Loss: 0.7163689518202094\n",
      "Epoch: 167, Loss: 0.7158727892384118\n",
      "Epoch: 168, Loss: 0.7153831769293545\n",
      "Epoch: 169, Loss: 0.714900007967372\n",
      "Epoch: 170, Loss: 0.7144231773226394\n",
      "Epoch: 171, Loss: 0.7139525818298909\n",
      "Epoch: 172, Loss: 0.713488120157537\n",
      "Epoch: 173, Loss: 0.7130296927771731\n",
      "Epoch: 174, Loss: 0.7125772019334699\n",
      "Epoch: 175, Loss: 0.7121305516144395\n",
      "Epoch: 176, Loss: 0.7116896475220711\n",
      "Epoch: 177, Loss: 0.7112543970433358\n",
      "Epoch: 178, Loss: 0.7108247092215513\n",
      "Epoch: 179, Loss: 0.7104004947281086\n",
      "Epoch: 180, Loss: 0.709981665834558\n",
      "Epoch: 181, Loss: 0.7095681363850496\n",
      "Epoch: 182, Loss: 0.7091598217691314\n",
      "Epoch: 183, Loss: 0.7087566388948989\n",
      "Epoch: 184, Loss: 0.7083585061625028\n",
      "Epoch: 185, Loss: 0.7079653434380022\n",
      "Epoch: 186, Loss: 0.7075770720275747\n",
      "Epoch: 187, Loss: 0.707193614652075\n",
      "Epoch: 188, Loss: 0.7068148954219421\n",
      "Epoch: 189, Loss: 0.7064408398124564\n",
      "Epoch: 190, Loss: 0.7060713746393438\n",
      "Epoch: 191, Loss: 0.7057064280347259\n",
      "Epoch: 192, Loss: 0.7053459294234155\n",
      "Epoch: 193, Loss: 0.7049898094995551\n",
      "Epoch: 194, Loss: 0.704638000203599\n",
      "Epoch: 195, Loss: 0.704290434699634\n",
      "Epoch: 196, Loss: 0.7039470473530423\n",
      "Epoch: 197, Loss: 0.7036077737084973\n",
      "Epoch: 198, Loss: 0.7032725504682983\n",
      "Epoch: 199, Loss: 0.7029413154710377\n",
      "Epoch: 200, Loss: 0.7026140076705982\n",
      "Epoch: 201, Loss: 0.702290567115481\n",
      "Epoch: 202, Loss: 0.7019709349284595\n",
      "Epoch: 203, Loss: 0.7016550532865586\n",
      "Epoch: 204, Loss: 0.7013428654013556\n",
      "Epoch: 205, Loss: 0.7010343154996009\n",
      "Epoch: 206, Loss: 0.7007293488041569\n",
      "Epoch: 207, Loss: 0.7004279115152487\n",
      "Epoch: 208, Loss: 0.7001299507920301\n",
      "Epoch: 209, Loss: 0.6998354147344562\n",
      "Epoch: 210, Loss: 0.6995442523654641\n",
      "Epoch: 211, Loss: 0.6992564136134543\n",
      "Epoch: 212, Loss: 0.6989718492950753\n",
      "Epoch: 213, Loss: 0.6986905110983045\n",
      "Epoch: 214, Loss: 0.6984123515658235\n",
      "Epoch: 215, Loss: 0.6981373240786843\n",
      "Epoch: 216, Loss: 0.6978653828402646\n",
      "Epoch: 217, Loss: 0.6975964828605072\n",
      "Epoch: 218, Loss: 0.6973305799404418\n",
      "Epoch: 219, Loss: 0.6970676306569848\n",
      "Epoch: 220, Loss: 0.6968075923480153\n",
      "Epoch: 221, Loss: 0.6965504230977205\n",
      "Epoch: 222, Loss: 0.6962960817222139\n",
      "Epoch: 223, Loss: 0.6960445277554135\n",
      "Epoch: 224, Loss: 0.6957957214351858\n",
      "Epoch: 225, Loss: 0.6955496236897457\n",
      "Epoch: 226, Loss: 0.695306196124313\n",
      "Epoch: 227, Loss: 0.6950654010080188\n",
      "Epoch: 228, Loss: 0.6948272012610595\n",
      "Epoch: 229, Loss: 0.6945915604420969\n",
      "Epoch: 230, Loss: 0.6943584427358981\n",
      "Epoch: 231, Loss: 0.6941278129412121\n",
      "Epoch: 232, Loss: 0.6938996364588809\n",
      "Epoch: 233, Loss: 0.6936738792801816\n",
      "Epoch: 234, Loss: 0.6934505079753936\n",
      "Epoch: 235, Loss: 0.6932294896825905\n",
      "Epoch: 236, Loss: 0.6930107920966502\n",
      "Epoch: 237, Loss: 0.6927943834584831\n",
      "Epoch: 238, Loss: 0.6925802325444715\n",
      "Epoch: 239, Loss: 0.6923683086561185\n",
      "Epoch: 240, Loss: 0.6921585816099035\n",
      "Epoch: 241, Loss: 0.6919510217273382\n",
      "Epoch: 242, Loss: 0.6917455998252237\n",
      "Epoch: 243, Loss: 0.6915422872061007\n",
      "Epoch: 244, Loss: 0.6913410556488939\n",
      "Epoch: 245, Loss: 0.6911418773997433\n",
      "Epoch: 246, Loss: 0.690944725163022\n",
      "Epoch: 247, Loss: 0.6907495720925347\n",
      "Epoch: 248, Loss: 0.6905563917828965\n",
      "Epoch: 249, Loss: 0.6903651582610858\n",
      "Epoch: 250, Loss: 0.6901758459781695\n",
      "Epoch: 251, Loss: 0.6899884298011982\n",
      "Epoch: 252, Loss: 0.6898028850052655\n",
      "Epoch: 253, Loss: 0.6896191872657322\n",
      "Epoch: 254, Loss: 0.6894373126506074\n",
      "Epoch: 255, Loss: 0.6892572376130882\n",
      "Epoch: 256, Loss: 0.6890789389842527\n",
      "Epoch: 257, Loss: 0.6889023939659015\n",
      "Epoch: 258, Loss: 0.6887275801235491\n",
      "Epoch: 259, Loss: 0.6885544753795594\n",
      "Epoch: 260, Loss: 0.6883830580064217\n",
      "Epoch: 261, Loss: 0.6882133066201666\n",
      "Epoch: 262, Loss: 0.6880452001739179\n",
      "Epoch: 263, Loss: 0.6878787179515787\n",
      "Epoch: 264, Loss: 0.687713839561646\n",
      "Epoch: 265, Loss: 0.6875505449311552\n",
      "Epoch: 266, Loss: 0.6873888142997503\n",
      "Epoch: 267, Loss: 0.687228628213874\n",
      "Epoch: 268, Loss: 0.6870699675210826\n",
      "Epoch: 269, Loss: 0.6869128133644737\n",
      "Epoch: 270, Loss: 0.6867571471772337\n",
      "Epoch: 271, Loss: 0.6866029506772949\n",
      "Epoch: 272, Loss: 0.6864502058621046\n",
      "Epoch: 273, Loss: 0.6862988950035018\n",
      "Epoch: 274, Loss: 0.6861490006427016\n",
      "Epoch: 275, Loss: 0.6860005055853801\n",
      "Epoch: 276, Loss: 0.6858533928968634\n",
      "Epoch: 277, Loss: 0.685707645897414\n",
      "Epoch: 278, Loss: 0.6855632481576167\n",
      "Epoch: 279, Loss: 0.6854201834938569\n",
      "Epoch: 280, Loss: 0.6852784359638938\n",
      "Epoch: 281, Loss: 0.6851379898625236\n",
      "Epoch: 282, Loss: 0.6849988297173323\n",
      "Epoch: 283, Loss: 0.6848609402845356\n",
      "Epoch: 284, Loss: 0.684724306544904\n",
      "Epoch: 285, Loss: 0.6845889136997705\n",
      "Epoch: 286, Loss: 0.6844547471671214\n",
      "Epoch: 287, Loss: 0.6843217925777659\n",
      "Epoch: 288, Loss: 0.6841900357715828\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = MySimpleNN(X_train_tensor)\n",
    "min_loss=float('inf')\n",
    "# define loop\n",
    "c=0\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # forward pass\n",
    "    y_pred = model.forward(X_train_tensor)\n",
    "    \n",
    "    # loss calculate\n",
    "    loss = model.loss_function(y_pred, y_train_tensor)\n",
    "    \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # parameters update\n",
    "    with torch.no_grad():\n",
    "        model.weights1 -= learning_rate * model.weights1.grad\n",
    "        model.bias1 -= learning_rate * model.bias1.grad\n",
    "        model.weights2 -= learning_rate * model.weights2.grad\n",
    "        model.bias2 -= learning_rate * model.bias2.grad\n",
    "        model.weights3 -= learning_rate * model.weights3.grad\n",
    "        model.bias3 -= learning_rate * model.bias3.grad\n",
    "        # model.weights4 -= learning_rate * model.weights4.grad\n",
    "        # model.bias4 -= learning_rate * model.bias4.grad\n",
    "    \n",
    "    # zero gradients\n",
    "    model.weights1.grad.zero_()\n",
    "    model.bias1.grad.zero_()\n",
    "    model.weights2.grad.zero_()\n",
    "    model.bias2.grad.zero_()\n",
    "    model.weights3.grad.zero_()\n",
    "    model.bias3.grad.zero_()\n",
    "    # model.weights4.grad.zero_()\n",
    "    # model.bias4.grad.zero_()\n",
    "    # print loss in each epoch\n",
    "    # if loss<1.5:\n",
    "    #     l=loss\n",
    "    #     learning_rate/=5\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')\n",
    "    \n",
    "    if min_loss-loss.item()>0.001:\n",
    "        c=0\n",
    "        min_loss=loss\n",
    "        mw1= model.weights1\n",
    "        mb1= model.bias1\n",
    "        mw2= model.weights2\n",
    "        mb2= model.bias2\n",
    "        mw3= model.weights3\n",
    "        mb3= model.bias3\n",
    "    elif c>5:\n",
    "        model.weights1= mw1\n",
    "        model.bias1= mb1\n",
    "        model.weights2=mw2\n",
    "        model.bias2=mb2\n",
    "        model.weights3=mw3\n",
    "        model.bias3=mb3\n",
    "        break\n",
    "    else:\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzJuqvFHdSCV"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z5EjQbXORCqd",
    "outputId": "62994071-5c69-4ef1-fef5-94e4a87792d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6491228342056274\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "with torch.no_grad():\n",
    "  y_pred = model.forward(X_test_tensor)\n",
    "  y_pred = (y_pred > 0.9).float()\n",
    "  accuracy = (y_pred == y_test_tensor).float().mean()\n",
    "  print(f'Accuracy: {accuracy.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model,input_size= X_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
